# fed-multimodal

The framework figure:

<div align="center">
 <img src="img/FedMultimodal.jpg" width="300px">
</div>



## Applications supported
* Speech Emotion Recognition
* Multimedia Action Recognition
* Human Activity Recognition

### Speech Emotion Recognition

Dataset | Modality | Paper | Num. of Speakers | Hours of data
|---|---|---|---|---|
MELD | A+T+V | [arxiv](https://arxiv.org/abs/1810.02508) | 260 |
MSP-Podcast | A+T(ASR) | [TAFFC'19](https://ecs.utdallas.edu/research/researchlabs/msp-lab/publications/Lotfian_2019_3.pdf) | >200 |


### Multimedia Action Recognition

Dataset | Modality | Paper | Num. of Instance | Hours of data
|---|---|---|---|---|
UCF101 | A+V | [arxiv](https://arxiv.org/abs/1212.0402) | 6810 |
MIT | A+V | [arxiv](https://arxiv.org/abs/1801.03150) | >100k |


